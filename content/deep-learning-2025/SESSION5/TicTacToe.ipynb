{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1p27hsU3gzuG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import pickle\n",
        "\n",
        "from enum import Enum\n",
        "import sys\n",
        "\n",
        "BOARD_ROW  = 3\n",
        "BOARD_COL  = 3\n",
        "WIN_LENGTH = 3\n",
        "\n",
        "# Learning iterations\n",
        "MAX_ITE = 0\n",
        "Vinit = 4.0\n",
        "\n",
        "MARKERNUMX =  1\n",
        "MARKERNUMO = -1\n",
        "\n",
        "class GAMESTATUS(Enum):\n",
        "    X_WINS  =  1\n",
        "    O_WINS  = -1\n",
        "    DRAW    =  2\n",
        "    ONGOING =  0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utilities\n",
        "\n",
        "# Find the player with the right to move based on the sum of the table, 1 is 'x', 0 is 'o'\n",
        "def currentPlayer(state):\n",
        "    return 'x' if (sum(state) == 0) else 'o' # player x or player o\n",
        "\n",
        "# Find the player's number representing the mark, 1 for player 1 and -1 for player 0\n",
        "def markerNumOnBoard(player):\n",
        "    return MARKERNUMX if player == 'x' else MARKERNUMO\n",
        "\n",
        "# Check if there is a streak of W values of xs or os in 1D arr\n",
        "def checkConsecutive(arr, W, player):\n",
        "    # Should replace o first because it is -1 so -111 will be wrongly considered a win for x\n",
        "    strarr = \"\".join(map(str, arr)).replace(str(MARKERNUMO), 'o').replace(str(MARKERNUMX), 'x')\n",
        "    if player*W in strarr:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# Check if the board is in terminal condition\n",
        "def terminalCheck(state):\n",
        "\n",
        "    board = np.array(state).reshape((BOARD_ROW, BOARD_COL))\n",
        "    \n",
        "    # Check the row and columns\n",
        "    for idx in range(BOARD_ROW):\n",
        "        if checkConsecutive(board[idx, :], WIN_LENGTH, 'x'):\n",
        "            return GAMESTATUS.X_WINS\n",
        "        if checkConsecutive(board[idx, :], WIN_LENGTH, 'o'):\n",
        "            return GAMESTATUS.O_WINS\n",
        "    for idx in range(BOARD_COL):\n",
        "        if checkConsecutive(board[:, idx], WIN_LENGTH, 'x'):\n",
        "            return GAMESTATUS.X_WINS\n",
        "        if checkConsecutive(board[:, idx], WIN_LENGTH, 'o'):\n",
        "            return GAMESTATUS.O_WINS\n",
        "\n",
        "    # Check all diagonals (↘ and ↙) of length ≥ W\n",
        "    for d in range(-BOARD_ROW, BOARD_COL):  # Diagonal offsets\n",
        "        if checkConsecutive(np.diagonal(board, offset=d), WIN_LENGTH, 'x'):\n",
        "            return GAMESTATUS.X_WINS\n",
        "        if checkConsecutive(np.diagonal(board, offset=d), WIN_LENGTH, 'o'):\n",
        "            return GAMESTATUS.O_WINS\n",
        "        \n",
        "    # Check all diagonals (↘ and ↙) of length ≥ W\n",
        "    for d in range(-BOARD_ROW, BOARD_COL):  # Diagonal offsets\n",
        "        if checkConsecutive(np.diagonal(np.fliplr(board), offset=d), WIN_LENGTH, 'x'):\n",
        "            return GAMESTATUS.X_WINS\n",
        "        if checkConsecutive(np.diagonal(np.fliplr(board), offset=d), WIN_LENGTH, 'o'):\n",
        "            return GAMESTATUS.O_WINS\n",
        "\n",
        "    # Check if the board is full (draw)\n",
        "    if not np.any(board == 0):\n",
        "        return GAMESTATUS.DRAW\n",
        "\n",
        "    return GAMESTATUS.ONGOING\n",
        "\n",
        "# Find the set of actions that can be taken from current state\n",
        "def findActionSet(state):\n",
        "    return [cidx for cidx, cellvalue in enumerate(state) if cellvalue == 0]\n",
        "\n",
        "# Apply the action on the current state and get the new state\n",
        "def applyAction(state, action):\n",
        "    next_state = copy.copy(state)\n",
        "    next_state[action] = markerNumOnBoard(currentPlayer(state))\n",
        "    assert(next_state != state)\n",
        "    return next_state\n",
        "\n",
        "# Determine the reward from the state\n",
        "def getReward(state, player):\n",
        "    \n",
        "    done = terminalCheck(state)\n",
        "    \n",
        "    if done == GAMESTATUS.ONGOING or done == GAMESTATUS.DRAW:\n",
        "        return 0\n",
        "    \n",
        "    if (done == GAMESTATUS.X_WINS and player == 'x')\\\n",
        "    or (done == GAMESTATUS.O_WINS and player == 'o'):\n",
        "        return 1\n",
        "    \n",
        "    if (done == GAMESTATUS.X_WINS and player == 'o')\\\n",
        "    or (done == GAMESTATUS.O_WINS and player == 'x'):\n",
        "        return -1\n",
        "    \n",
        "    assert(False)    # Just make sure that we do not forget any logic here.\n",
        "    return 0\n",
        "\n",
        "# Find the set of states s' that the board will transition to after the agent takes an action\n",
        "def possibleNextStateIdx(states, state, action):\n",
        "\n",
        "    # Create a list of possible states that may occur after 'state'\n",
        "    nextPossibleStateIdx = []\n",
        "\n",
        "    # Apply the action and determine the possible next state\n",
        "    next_state = applyAction(state, action)\n",
        "\n",
        "    # Check the terminality of the 'next_state'\n",
        "    done = terminalCheck(next_state)\n",
        "\n",
        "    # If 'next_state' is terminal, add the 'next_state' to the list and return\n",
        "    if done != GAMESTATUS.ONGOING:\n",
        "        nextPossibleStateIdx.append(states.index(next_state))\n",
        "        return nextPossibleStateIdx\n",
        "\n",
        "    # If the state is not terminal, find the 'legal_opponent_actions' from the 'next state',\n",
        "    # apply each action in 'legal_opponent_actions' to 'next_state' and add 'next_next_state' to the list\n",
        "    if done == GAMESTATUS.ONGOING:\n",
        "        legal_opponent_actions = findActionSet(next_state)\n",
        "        for action in legal_opponent_actions:\n",
        "            next_next_state = applyAction(next_state, action)\n",
        "            nextPossibleStateIdx.append(states.index(next_next_state))\n",
        "\n",
        "    # Return the next possible state\n",
        "    return nextPossibleStateIdx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzpSxZpddHCA",
        "outputId": "4c5a2c4d-a4ac-40ab-b6d9-b0fc9d0d1e66"
      },
      "outputs": [],
      "source": [
        "# Create the value tables for player x and player o\n",
        "\n",
        "import copy\n",
        "import pickle\n",
        "\n",
        "# Initialize the memories\n",
        "state = [0 for idx in range(BOARD_ROW*BOARD_COL)]\n",
        "Vx = Vinit\n",
        "Vo = Vinit\n",
        "\n",
        "memory = [[state], [Vx], [Vo]]\n",
        "\n",
        "def TabulateStates(state):\n",
        "    # Find all the possible actions from the current states\n",
        "    actionSet = findActionSet(state)\n",
        "    # Apply the action, then look further into the futher action\n",
        "    for action in actionSet:\n",
        "        new_state = applyAction(state, action)\n",
        "        if new_state not in memory[0]:\n",
        "            done = terminalCheck(new_state)\n",
        "            # If the state is not terminal, go further till hitting a terminal state\n",
        "            if done == GAMESTATUS.ONGOING:\n",
        "                Vx, Vo = Vinit, Vinit\n",
        "                TabulateStates(new_state)\n",
        "            # If it's a win, reward 1 to winner and -1 to loser\n",
        "            elif done == GAMESTATUS.X_WINS:\n",
        "                Vx, Vo =  1, -1\n",
        "            elif done == GAMESTATUS.O_WINS:\n",
        "                Vx, Vo = -1,  1\n",
        "            # If it's a draw, reward 0 to both\n",
        "            elif done == GAMESTATUS.DRAW:\n",
        "                Vx, Vo =  0,  0\n",
        "\n",
        "            # code = \"\".join(map(str, new_state[:]))\n",
        "            # code = code.replace('-1', 'B')\n",
        "            # code = code.replace('1', 'A')\n",
        "            # print(\"adding\", code, done)\n",
        "\n",
        "            memory[0].append(new_state)\n",
        "            memory[1].append(Vx)\n",
        "            memory[2].append(Vo)\n",
        "\n",
        "TabulateStates(state)\n",
        "\n",
        "print('States successfully tabulated with initial values!')\n",
        "print('Size of memory: ', len(memory[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVQSl7H6dON6",
        "outputId": "c3fd2c6c-1c29-4dbb-c975-2cc9d89e376f"
      },
      "outputs": [],
      "source": [
        "# Value iteration for best strategy against a random player\n",
        "\n",
        "\n",
        "# with open('state_value_init.pkl', 'rb') as file:\n",
        "#     memory = pickle.load(file)\n",
        "\n",
        "states = memory[0]\n",
        "Vx = memory[1]\n",
        "Vo = memory[2]\n",
        "\n",
        "gamma = 0.9\n",
        "\n",
        "# Iterate for 5 times\n",
        "for k in range(MAX_ITE):\n",
        "    \n",
        "    # Vx_k = Vx\n",
        "    # Vo_k = Vo\n",
        "\n",
        "    # Rate of change during each iteration\n",
        "    dVmax = -np.inf\n",
        "\n",
        "    # Iterate over the states\n",
        "    for state in states:\n",
        "\n",
        "        # Check the terminal category\n",
        "        done = terminalCheck(state)\n",
        "\n",
        "        # If the state is a terminal state, no need to update, otherwise perform value iteration\n",
        "        if done != GAMESTATUS.ONGOING:\n",
        "            continue\n",
        "        \n",
        "        # Index of the state under evaluation in the table\n",
        "        sidx = states.index(state)\n",
        "\n",
        "        # Determine the player's turn\n",
        "        player = currentPlayer(state)\n",
        "\n",
        "        # Find the legal actions at this state\n",
        "        legal_actions = findActionSet(state)\n",
        "        \n",
        "        # Create a buffer for state-action value\n",
        "        Qsa_buf = []\n",
        "\n",
        "        # Find the state-action value for each action\n",
        "        for action in legal_actions:\n",
        "\n",
        "            # Identify the next outcomes\n",
        "            nsidx = possibleNextStateIdx(states, state, action)\n",
        "\n",
        "            # Probability of opponent making a counter move\n",
        "            p = 1 / len(nsidx)\n",
        "            Qsa = 0\n",
        "\n",
        "            # Calculate the state-action value as an expectation\n",
        "            for idx in nsidx:\n",
        "                next_state = states[idx]\n",
        "                value = Vx[idx] if player == 'x' else Vo[idx]\n",
        "                # print(state, legal_actions, action, next_state)\n",
        "                reward = getReward(next_state, player)\n",
        "                Qsa += p * (reward + gamma * value)\n",
        "\n",
        "            # Store that state-action value\n",
        "            Qsa_buf.append(round(Qsa, 3))\n",
        "\n",
        "        # Find the highest state-action value\n",
        "        maxQsa = max(Qsa_buf)\n",
        "\n",
        "        if player == 'x':\n",
        "            dVmax = max(dVmax, abs(Vx[sidx] - maxQsa))\n",
        "            Vx[sidx] = maxQsa\n",
        "        else:\n",
        "            dVmax = max(dVmax, abs(Vo[sidx] - maxQsa))\n",
        "            Vo[sidx] = maxQsa\n",
        "\n",
        "    print(f'Iteration {k}, change: {dVmax:.2f}')\n",
        "\n",
        "state_action = [states, Vx, Vo]\n",
        "with open('state_value_init.pkl', 'wb') as file:\n",
        "    pickle.dump(state_action, file)\n",
        "\n",
        "print('Successfully iterated over the states until convergence!')\n",
        "print('Enjoy it!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6seZ3Haufxm"
      },
      "outputs": [],
      "source": [
        "#######################################################################\n",
        "#\n",
        "# Tic-Tac-Toe interactive environment\n",
        "#\n",
        "#######################################################################\n",
        "\n",
        "class Game():\n",
        "\n",
        "    def __init__(self, debug=False):\n",
        "        self.done = GAMESTATUS.ONGOING                   # 0 for not done, 1 for X wins, -1 for O wins, -2 for illegal move, 2 for draw\n",
        "        self.debug = debug\n",
        "\n",
        "    def _draw(self):\n",
        "        board_matrix = np.array(self.board).reshape((BOARD_ROW, BOARD_COL))\n",
        "        # p1: x  p2: o\n",
        "        for i in range(0, BOARD_ROW):\n",
        "            print('----' * BOARD_COL + '-')\n",
        "            out = '|'\n",
        "            for j in range(0, BOARD_COL):\n",
        "                if board_matrix[i, j] == 1:\n",
        "                    token = '\\033[32m X \\033[0m'\n",
        "                if board_matrix[i, j] == -1:\n",
        "                    token = '\\033[31m O \\033[0m'\n",
        "                if board_matrix[i, j] == 0:\n",
        "                    token = f'{i*BOARD_ROW + j:2d} '\n",
        "                out += token + '| '\n",
        "            print(out)\n",
        "        print('----' * BOARD_COL + '-')\n",
        "\n",
        "    def _computeDone(self):\n",
        "        self.done = terminalCheck(self.board)\n",
        "\n",
        "\n",
        "    def _computeReward(self):\n",
        "      return 0\n",
        "\n",
        "    def step(self, action, player_who_acts):\n",
        "        \n",
        "        assert(currentPlayer(self.board) == player_who_acts)\n",
        "        \n",
        "        # Check for the illegal move\n",
        "        if self.board[action] != 0:\n",
        "            self.done = -2\n",
        "        else:\n",
        "            self.board[action] = markerNumOnBoard(player_who_acts)\n",
        "            self._computeDone()\n",
        "\n",
        "        self._computeReward()\n",
        "\n",
        "        if self.debug:\n",
        "            self._draw()\n",
        "\n",
        "        return self.board, 0, self.done\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = [0 for idx in range(BOARD_ROW*BOARD_COL)]\n",
        "        if self.debug:\n",
        "            self._draw()\n",
        "        return self.board\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GBN061R5SKHc",
        "outputId": "4ae35d85-1ec3-44b3-d8e8-849e8ca4cbff"
      },
      "outputs": [],
      "source": [
        "#######################################################################\n",
        "#\n",
        "# A simple human-AI game interface (needs to be improved :))\n",
        "#\n",
        "#######################################################################\n",
        "\n",
        "# import tictactoe\n",
        "import random\n",
        "import pickle\n",
        "# from utils import *\n",
        "import time\n",
        "\n",
        "\n",
        "print('\\n\\TicTacToe by Value Iteration!')\n",
        "print('Good luck!')\n",
        "\n",
        "def getPlayerChoice():\n",
        "    human_player = None\n",
        "    count = 0\n",
        "    # Initialize the game\n",
        "    while(human_player is None):\n",
        "        choice = input(f'\\nAttempt#{count}. X will go first. Please select O/X:\\n\\t O. Play as O. \\n\\t X. Play as X.\\n')\n",
        "        if choice.lower() == 'o':\n",
        "            human_player = 'o'\n",
        "        elif choice.lower() == 'x':\n",
        "            human_player = 'x'\n",
        "        else:\n",
        "            print(\"Wrong choice, chose 'O/o' or 'X/x'.\")\n",
        "        count += 1\n",
        "        if count > 5:\n",
        "            break\n",
        "    return human_player\n",
        "\n",
        "def getHumanMove(state):\n",
        "    \n",
        "    legal_actions = findActionSet(state)\n",
        "    \n",
        "    count = 0\n",
        "    print(f\"Try {count}. Legal actions for human: {legal_actions}\")\n",
        "    while True:\n",
        "        human_move = None\n",
        "        try:\n",
        "            human_move = int(input('Please make a move: '))\n",
        "        except ValueError:\n",
        "            human_move = None\n",
        "\n",
        "        if human_move not in legal_actions:\n",
        "            print(f\"Attempt#{count}. Illegal move. Please chose in {legal_actions}\")\n",
        "        else:\n",
        "            print(f\"Human chooses action {human_move}\")\n",
        "            return human_move\n",
        "        count += 1\n",
        "        if count > 5:\n",
        "            print(\"Exiting\")\n",
        "            sys.exit()  # Shutdown the kernel\n",
        "\n",
        "    return legal_actions[0]\n",
        "\n",
        "def policy(state, ai_player):\n",
        "    legal_actions = findActionSet(state)\n",
        "    Qsa_buf = []\n",
        "    for action in legal_actions:\n",
        "        nsidx = possibleNextStateIdx(states, state, action)\n",
        "        p = 1 / len(nsidx)\n",
        "        Qsa = 0\n",
        "        for sidx in nsidx:\n",
        "            ai_statevalue = Vo[sidx] if ai_player == 'o' else Vx[sidx]\n",
        "            reward = getReward(states[sidx], ai_player)\n",
        "            Qsa += p * (reward + gamma * ai_statevalue)\n",
        "        Qsa_buf.append(round(Qsa, 3))\n",
        "    action = legal_actions[Qsa_buf.index(max(Qsa_buf))]\n",
        "    return action, legal_actions, Qsa_buf\n",
        "    \n",
        "\n",
        "# Create the environment\n",
        "env = Game(debug=True)\n",
        "\n",
        "# Export the memories as list\n",
        "# with open(f'state_value_{BOARD_ROW}x{BOARD_COL}.pkl', 'rb') as file:\n",
        "#     state_action = pickle.load(file)\n",
        "\n",
        "states = state_action[0]\n",
        "Vx = state_action[1]\n",
        "Vo = state_action[2]\n",
        "score_table = [0, 0]    # human, AI\n",
        "\n",
        "while True:\n",
        "\n",
        "    # Prompt human's preferred symbol\n",
        "    human_player = getPlayerChoice()\n",
        "    ai_player = 'x' if human_player == 'o' else 'o'\n",
        "\n",
        "    init = True\n",
        "    done = GAMESTATUS.ONGOING\n",
        "    state = env.reset()\n",
        "\n",
        "    # Start playing\n",
        "    while done == GAMESTATUS.ONGOING:\n",
        "        \n",
        "        # If human goes first\n",
        "        if (init and human_player == 'x'):\n",
        "            init = False\n",
        "            human_move = getHumanMove(state)\n",
        "            state, reward, done = env.step(human_move, player_who_acts = human_player)\n",
        "            continue\n",
        "        elif init:  # If AI goes first\n",
        "            init = False\n",
        "            action, legal_actions, Qsa_buf = policy(state, ai_player)\n",
        "            print(f'AI chooses action {action} ...')\n",
        "            state, reward, done = env.step(action, player_who_acts = ai_player)\n",
        "            human_move = getHumanMove(state)\n",
        "            state, reward, done = env.step(human_move, player_who_acts = human_player)\n",
        "\n",
        "        print('VI enacting policy...')\n",
        "        action, legal_actions, Qsa_buf = policy(state, ai_player)\n",
        "        print('\\tlegal acttion', legal_actions)\n",
        "        print('\\taction values', Qsa_buf)\n",
        "        print('AI choses action:', action)\n",
        "        \n",
        "        # Apply the action\n",
        "        state, reward, done = env.step(action, player_who_acts = ai_player)\n",
        "        \n",
        "        # Human moves\n",
        "        if done == GAMESTATUS.ONGOING:\n",
        "            human_move = getHumanMove(state)\n",
        "            state, reward, done = env.step(human_move, player_who_acts = human_player)\n",
        "\n",
        "    victor = None\n",
        "    if done == GAMESTATUS.X_WINS:\n",
        "        victor = 'x'\n",
        "    elif done == GAMESTATUS.O_WINS:\n",
        "        victor = 'o'\n",
        "\n",
        "    if victor == human_player:\n",
        "        score_table[0] += 1\n",
        "    elif done != GAMESTATUS.DRAW:\n",
        "        score_table[1] += 1\n",
        "\n",
        "    print(\"\\n\\nGame Over!\")\n",
        "    print('Human Score: ', score_table[0])\n",
        "    print('AI Score: ' , score_table[1], '\\n\\n')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
