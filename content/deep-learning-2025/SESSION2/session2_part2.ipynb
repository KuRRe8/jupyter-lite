{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ntu-dl-bootcamp/deep-learning-2025/blob/main/SESSION2/session2_part2.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AfoRDLwVUiF"
      },
      "source": [
        "# Datasets and Dataloaders\n",
        "\n",
        "PyTorch has `torch.utils.data.Dataloader` and `torch.utils.data.Dataset` to allow you to use pre-loaded data as well as your own data.\n",
        "\n",
        "`Dataset` stores the samples and their corresponding labels.\n",
        "\n",
        "`Dataloader` wraps an _iterable_ around the `Dataset` for easy access to samples. An iterable in python is any object which can be looped over or iterated over with the help of a for loop.\n",
        "\n",
        "PyTorch provides a number of pre-loaded datasets. You can find them here: [Image Datasets](https://pytorch.org/vision/stable/datasets.html), [Text Datasets](https://pytorch.org/text/stable/datasets.html), and [Audio Datasets](https://pytorch.org/audio/stable/datasets.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWxqggWBX1cB"
      },
      "source": [
        "## Loading a Dataset\n",
        "\n",
        "The MNIST (Modified National Institute of Standards and Technology) dataset is a collection of 70,000 images of handwritten digits (0 through 9).\n",
        "\n",
        "Each image is:\n",
        "- Size: 28x28 pixels (small, grayscale images)\n",
        "- Total Images: 60,000 for training and 10,000 for testing\n",
        "- Labels: Each image is labeled with the digit it represents (0 to 9)\n",
        "\n",
        "The MNIST dataset is widely used for learning and testing basic image processing and machine learning techniques, especially in deep learning. Since the images are simple and low-resolution, the dataset allows us to build and train models quickly.\n",
        "\n",
        "We will load the MNIST dataset from `torchvision`. Read more about this dataset [here](https://en.wikipedia.org/wiki/MNIST_database)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvWcdvSOVxjU"
      },
      "outputs": [],
      "source": [
        "# Import the necessary modules from torchvision\n",
        "from torchvision import datasets  # for accessing popular datasets\n",
        "from torchvision.transforms import ToTensor  # for converting images to PyTorch tensors\n",
        "\n",
        "# Download and prepare the training data\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",  # 'root' is the directory where the dataset will be stored\n",
        "    train=True,  # 'train=True' specifies that we want the training set\n",
        "    download=True,  # 'download=True' will download the dataset if it's not already present\n",
        "    transform=ToTensor(),  # 'transform=ToTensor()' converts the images to PyTorch tensors (needed for PyTorch models)\n",
        ")\n",
        "\n",
        "# Download and prepare the test data\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",  # Store the test data in the same directory as training data\n",
        "    train=False,  # 'train=False' specifies that we want the test set\n",
        "    download=True,  # 'download=True' will download the test dataset if it's not already present\n",
        "    transform=ToTensor(),  # Convert test images to tensors, just like the training data\n",
        ")\n",
        "\n",
        "# Explanation:\n",
        "# - datasets.MNIST() provides access to the MNIST dataset, with options to load either training or test data.\n",
        "# - ToTensor() transforms each image from a PIL image format (used by default) to a PyTorch tensor.\n",
        "# - The 'root' parameter specifies where the data should be saved on your system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84rMBLuMZfJD",
        "outputId": "9ea3911a-776e-43cf-baa1-f95cbe167b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in training data  60000\n",
            "Number of samples in test data  10000\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of samples in training data \", len(training_data))\n",
        "print(\"Number of samples in test data \", len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63vl9X_hbHP0",
        "outputId": "4abd0c7c-8306-40f3-ba80-ec388c082079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image shape before np.squeeze: torch.Size([1, 28, 28])\n",
            "Image shape before np.squeeze: torch.Size([28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary module for plotting images\n",
        "import matplotlib.pyplot as plt  # 'matplotlib.pyplot' is a library for creating visualizations in Python\n",
        "\n",
        "# Access the 10th image and its label from the training dataset\n",
        "image, label = training_data[\n",
        "    10\n",
        "]  # 'training_data[10]' retrieves the 10th image and its label from the dataset\n",
        "\n",
        "# Print the shape of the image tensor\n",
        "print(\n",
        "    f\"Image shape before np.squeeze: {image.shape}\"\n",
        ")  # dimensions of the image tensor before any modifications\n",
        "\n",
        "# Remove the single color channel dimension from the image tensor\n",
        "image = (\n",
        "    image.squeeze()\n",
        ")  # 'squeeze()' removes extra dimensions of size 1 (from [1, 28, 28] to [28, 28])\n",
        "\n",
        "# Print the shape of the image tensor after squeezing\n",
        "print(f\"Image shape before np.squeeze: {image.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "q88dR3tfGBPV",
        "outputId": "d31c5021-4995-492f-aa5e-4cf766752ef7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 3\n"
          ]
        }
      ],
      "source": [
        "# Display the image using matplotlib\n",
        "plt.imshow(image, cmap=\"gray\")  # 'cmap='gray'' shows it in grayscale\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")\n",
        "\n",
        "# TODO: Try to visualise a different sample from the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_IJ3lSGbjrb"
      },
      "source": [
        "## Preparing your data for training using DataLoaders\n",
        "\n",
        "The `Dataset` we created above retrieves the data one sample at a time. While training a model, we typically want to\n",
        "1. pass samples in **minibatches**,\n",
        "2. reshuffle the data at every epoch to **reduce model overfitting** and\n",
        "3. Use python's `multiprocessing` to **speed up data retrieval**\n",
        "\n",
        "A dataloader is an _iterable_ that does these things for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_VIlqzFaqT5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D9vtcvndAwr"
      },
      "source": [
        "We have loaded our dataset into the `Dataloader` and can iterate through the dataset as needed. Each iteration below returns a **batch** of `train_features` and `train_labels`. After we iterate over all batches, the data will **shuffled**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxJFfJQUcruN",
        "outputId": "ad8096dd-5c8b-4ea5-cd32-ea1c71870961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "p4KwSlkRdquy",
        "outputId": "23c4d738-5471-4a8d-a229-621c841c3c20"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 4\n"
          ]
        }
      ],
      "source": [
        "# Visualising one image from the selected batch\n",
        "\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")\n",
        "\n",
        "# TODO: Try to visualise a different sample from this batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izv4-F3He1Og"
      },
      "source": [
        "# Build the Neural Network\n",
        "\n",
        "Neural networks contains layers that perform various operations on data. All the building blocks that you need to build a neural network are available in `torch.nn`.\n",
        "\n",
        "Every module in PyTorch will be a subclass of `nn.Module`. A neural network is itself a module that consists of other modules (layers). This **nested structure** allows us to build complex architectures easily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fNQrmFyflkz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW80AIgEftUZ",
        "outputId": "d50a2ad2-cbed-48d6-bc3a-4d373531d388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "# check if GPU is availble\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beH1p35uG2dm"
      },
      "source": [
        "If you see \"Using cpu device\" in the second line in the previous cell's output, change your runtime to use a GPU.\n",
        "\n",
        "In colab,\n",
        "1. Go to \"Runtime\" tab\n",
        "2. Select \"Change runtime type\"\n",
        "3. Select \"T4 GPU\" under \"Hardware Accelerator\"\n",
        "4. ⚠️ Wait for the run time to change and run all the previous cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daZ_MXbjgjGU"
      },
      "source": [
        "Next, we need to define our model by creating a python class. The model class should be a subclass of `nn.Module`.\n",
        "\n",
        "In the `__init__` method in our class, we can **initialise our neural network**. We need to define the **operations we need to perform on the input data** in the `forward` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyPYsmsZgKz6"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfhz_6KthZH0",
        "outputId": "534fe1e3-074c-42e6-be4d-a5978b3d6633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create an object of the model class and move that object to the `device` we\n",
        "# defined earlier\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "6seQ939Ehjki",
        "outputId": "5dbadcc9-d772-4ae5-cf0e-4b0c547ea7cc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 5\n",
            "\n",
            "Logits: tensor([[ 0.0182,  0.0267, -0.0011,  0.0528, -0.0236, -0.0067,  0.0334, -0.0234,\n",
            "          0.0583,  0.0306]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Predicted probabilities: tensor([[0.1001, 0.1010, 0.0982, 0.1037, 0.0960, 0.0977, 0.1017, 0.0961, 0.1042,\n",
            "         0.1014]], grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "Predicted class: tensor([8])\n"
          ]
        }
      ],
      "source": [
        "# To use this model, we pass the input data.\n",
        "img, label = training_data[0]\n",
        "\n",
        "# visualising the image\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\\n\")\n",
        "\n",
        "# Move the image tensor to the specified device (CPU or GPU)\n",
        "img = img.to(\n",
        "    device\n",
        ")  # 'img.to(device)' moves the image to the device (GPU or CPU) to match where the model is located.\n",
        "\n",
        "# Pass the image through the model to get the raw output (logits)\n",
        "logits = model(\n",
        "    img\n",
        ")  # 'model(img)' performs a forward pass through the model with 'img' as input, returning the raw output (logits).\n",
        "print(\n",
        "    f\"Logits: {logits}\\n\"\n",
        ")  # Print the raw output, which represents unnormalized scores for each class.\n",
        "\n",
        "# Convert logits to probabilities\n",
        "predicted_probabilities = nn.Softmax(\n",
        "    dim=1\n",
        ")(\n",
        "    logits\n",
        ")  # 'Softmax(dim=1)' applies the softmax function to logits to get probabilities. 'dim=1' ensures the function is applied across each class.\n",
        "print(\n",
        "    f\"Predicted probabilities: {predicted_probabilities}\\n\"\n",
        ")  # Print the predicted probabilities for each class, which now sum to 1.\n",
        "\n",
        "# Determine the predicted class by finding the index with the highest probability\n",
        "predicted_class = torch.argmax(\n",
        "    predicted_probabilities, dim=1\n",
        ")  # 'argmax' finds the class index with the highest probability, indicating the model's prediction.\n",
        "print(f\"Predicted class: {predicted_class}\")  # Print the predicted class index.\n",
        "\n",
        "# TODO: Try with another image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ4fwHiCm8A3"
      },
      "source": [
        "## What happens to the input at each layer in the network?\n",
        "\n",
        "Let us create a sample minibatch of 3 random images, each of size 28 x 28 and pass it through each layer in the neural network.\n",
        "\n",
        "```\n",
        "NeuralNetwork(\n",
        "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
        "  (linear_relu_stack): Sequential(\n",
        "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
        "    (1): ReLU()\n",
        "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
        "    (3): ReLU()\n",
        "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
        "  )\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RJQy7-njEE6",
        "outputId": "8f60aac4-7092-4f85-8f4e-9c5025762024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Create a minibatch containing 3 random images of size 28 x 28\n",
        "input_minibatch = torch.rand(3, 28, 28)\n",
        "print(input_minibatch.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoVcmxHOoK61"
      },
      "source": [
        "### nn.Flatten\n",
        "\n",
        "Let us initialise a `nn.Flatten` module. It converts each 28 x 28 image into a contiguous array of 784 pixels each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXTPUy1cn-O0",
        "outputId": "0ec787bd-7508-4ec1-8094-5629fc99f9f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ],
      "source": [
        "flatten = nn.Flatten()  # initialise the flatten module\n",
        "flat_image = flatten(\n",
        "    input_minibatch\n",
        ")  # pass the input minibatch through the initialised module\n",
        "print(flat_image.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN94eOX1okRh"
      },
      "source": [
        "### nn.Linear\n",
        "\n",
        "The linear module applies a linear transformation to the input using its stored weights and biases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Ewd1lIoecJ",
        "outputId": "576cdcb1-d0ae-47c3-9e17-de16be5ed46f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 512])\n"
          ]
        }
      ],
      "source": [
        "layer1 = nn.Linear(in_features=28 * 28, out_features=512)  # initialise the linear layer\n",
        "hidden1 = layer1(\n",
        "    flat_image\n",
        ")  # pass the output from previous flatten layer through the linear layer\n",
        "print(hidden1.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uH_hKCCpIr0"
      },
      "source": [
        "## nn.ReLU\n",
        "\n",
        "Non-linear activation functions are what creates the complex mappings between the model's inputs and outputs. They are applied after linear transformations to introduce non-linearity.\n",
        "\n",
        "In this model, we use the `nn.ReLU` between our layers. There are other non-linear activation functions like `nn.Sigmoid` and `nn.Tanh`.\n",
        "\n",
        "Read more: [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html), [nn.Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html), [nn.Tanh](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37f4kWoIoztq",
        "outputId": "648cc173-665e-4584-cdb3-1b35947fcfc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before ReLU: tensor([[-0.0719, -0.2445, -0.6022,  ...,  0.3872,  1.0010,  0.0453],\n",
            "        [-0.2120, -0.1619, -0.7970,  ...,  0.0897,  0.6388,  0.1026],\n",
            "        [-0.2407, -0.4716, -0.4279,  ...,  0.2648,  0.3774, -0.2786]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.3872, 1.0010, 0.0453],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0897, 0.6388, 0.1026],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.2648, 0.3774, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "relu = nn.ReLU()\n",
        "hidden1 = relu(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")\n",
        "\n",
        "# TODO: Notice what happened to the negative values in the input before they are passed through ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRAoOyPjqqTg"
      },
      "source": [
        "## nn.Sequential\n",
        "\n",
        "`nn.Sequential` is an **ordered** container of modules. The data is passed through all the modules in the same order as they are defined.\n",
        "\n",
        "You can use sequential containers to put together a **block** containing many layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2OVqUf_qaQU",
        "outputId": "aa7ca1b0-b8bf-4934-d092-b1a164bb335b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input mini batch: torch.Size([3, 28, 28])\n",
            "Logits: torch.Size([3, 10])\n"
          ]
        }
      ],
      "source": [
        "block1 = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28 * 28, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 10),\n",
        ")\n",
        "\n",
        "input_image = torch.rand(3, 28, 28)\n",
        "print(f\"Input mini batch: {input_image.size()}\")\n",
        "logits = block1(input_image)\n",
        "print(f\"Logits: {logits.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gZyZOHcruCN"
      },
      "source": [
        "## nn.Softmax\n",
        "\n",
        "The last linear layer of the neural network returns logits. Logits are raw values in [-infty, +infty]. These logits are passed into the softmax module.\n",
        "\n",
        "Softmax scales the logits to [0, 1], representing the **model's predicted probabilities** for each class.\n",
        "\n",
        "`dim` parameter indicates the axis along which the values should sum to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT1HMvWZrf6F",
        "outputId": "a2e02852-7080-4468-f4f5-12fdd2712d15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits\n",
            "tensor([[ 0.0392, -0.0208, -0.1409, -0.0785, -0.0511,  0.0301,  0.0485,  0.0512,\n",
            "         -0.0321,  0.0561],\n",
            "        [ 0.0423, -0.0090, -0.1551, -0.1121, -0.0761,  0.0696,  0.0715,  0.0168,\n",
            "         -0.0260,  0.0009],\n",
            "        [ 0.0373, -0.0219, -0.1215, -0.0368, -0.0728,  0.0113,  0.0498,  0.0391,\n",
            "         -0.0285, -0.0297]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Predicted probabilities\n",
            "tensor([[0.1048, 0.0987, 0.0875, 0.0932, 0.0958, 0.1039, 0.1058, 0.1061, 0.0976,\n",
            "         0.1066],\n",
            "        [0.1059, 0.1006, 0.0869, 0.0908, 0.0941, 0.1088, 0.1091, 0.1032, 0.0989,\n",
            "         0.1016],\n",
            "        [0.1055, 0.0994, 0.0900, 0.0979, 0.0945, 0.1028, 0.1068, 0.1057, 0.0988,\n",
            "         0.0986]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probabilities = softmax(logits)\n",
        "print(f\"Logits\\n{logits}\\n\")\n",
        "print(f\"Predicted probabilities\\n{pred_probabilities}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNvcI0Du3U6F"
      },
      "source": [
        "## Mini Challenge\n",
        "\n",
        "![image](https://github.com/ntu-dl-bootcamp/deep-learning-2025/raw/main/SESSION2/mini-challenge-session-2.png)\n",
        "\n",
        "1. Implement the neural network shown in the image above using Pytorch.\n",
        "2. Train this neural network using suitable hyper parameters\n",
        "3. Compare the performance of this new neural network with the one before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQkd3ymes7de"
      },
      "source": [
        "## Model parameters\n",
        "\n",
        "Many layers inside a neural network are parameterised. This means that they have associated weights and biases that are optimised during training.\n",
        "\n",
        "`nn.Module` tracks all the parameters inside a model object. This can be accessed using the model's `parameters()` and `named_parameters()` methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3O_i67KtgiB",
        "outputId": "728ee7c5-5c71-461a-bf8a-83d6658bc794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_hbJ8tlsgaT",
        "outputId": "646e23d4-1a97-4c51-8d2e-9f4bcc66f868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0226, -0.0274,  0.0055,  ..., -0.0342, -0.0107,  0.0145],\n",
            "        [-0.0290, -0.0258,  0.0072,  ...,  0.0328,  0.0231,  0.0225]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0256, -0.0135], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0016,  0.0280, -0.0433,  ...,  0.0249, -0.0177,  0.0295],\n",
            "        [ 0.0430, -0.0235, -0.0181,  ..., -0.0234,  0.0365, -0.0255]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0365, -0.0242], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0158,  0.0212, -0.0124,  ...,  0.0249, -0.0069, -0.0068],\n",
            "        [-0.0048,  0.0417,  0.0206,  ...,  0.0163,  0.0324,  0.0302]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0269,  0.0435], grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIxBFWs0uAER"
      },
      "source": [
        "# Optimising the model's parameters\n",
        "\n",
        "We now have a model and the data to train the model. We can train, validate and test our model by optimising the parameters on our data.\n",
        "\n",
        "Training a model is an iterative process. In each iteration,\n",
        "1. the model makes a guess about the output\n",
        "2. calculates the error in the guess (the loss)\n",
        "3. collects the derivatives of the error with respect to the parameters\n",
        "4. optimises these paramters using gradient descent.\n",
        "\n",
        "## Hyperparameters\n",
        "\n",
        "Hyperparameters are adjustable parameters that lets us control the optimisation process. Hyperparameter values can impact the model training and convergence rates.\n",
        "\n",
        "We can define these hyperparameters for training our model:\n",
        "1. **Number of epochs** - number of times to iterate over our training set.\n",
        "2. **Batch size** - number of input samples propagated through the network before the model parameters are updated.\n",
        "3. **Learning rate** - how much to update the models parameters at each batch / epoch. Smaller values yield slow learning speed, while large values may result in unpredictable behavior during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgzqm7J0teHU"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16v62WF2vvUB"
      },
      "source": [
        "## Optimisation loop\n",
        "Using these hyperparamters, we can train and optimise the paramters of our model with an optimisation loop. Each iteration of the optimisation loop is called as an **epoch**.\n",
        "\n",
        "Each epoch has two parts\n",
        "1. Iterate over the training loop and update the parameters\n",
        "2. Iterate over the test / validation loop and check if the model's performance is improving.\n",
        "\n",
        "Two important concepts used in the training loop are the loss function and the optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp1EmysNw0_V"
      },
      "source": [
        "# Loss function\n",
        "\n",
        "When presented with some training data, our **untrained network** is likely not to give the correct answer.\n",
        "\n",
        "Loss function measures the **degree of dissimilarity of obtained result to the target value**, and it is the loss function that we want to **minimize** during training.\n",
        "\n",
        "To calculate the loss we make a prediction using the inputs of our given data sample and compare it against the true data label value.\n",
        "\n",
        "Common loss functions\n",
        "1. [nn.MSELoss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss) (Mean Square Error) for regression tasks\n",
        "2. [nn.NLLLoss](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss) (Negative Log Likelihood) for classification\n",
        "3. [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) combines `nn.LogSoftmax` and `nn.NLLLoss`.\n",
        "\n",
        "We will use the Cross Entropy Loss, which will normalise the logits and compute the prediction error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCwdivyPvtU-"
      },
      "outputs": [],
      "source": [
        "# initialise the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUTADFRRyDPh"
      },
      "source": [
        "## Optimiser\n",
        "\n",
        "Optimization is the process of **adjusting model parameters to reduce model error in each training step**.\n",
        "\n",
        "Optimization algorithms define how this process is performed (in this example we use Stochastic Gradient Descent).\n",
        "\n",
        "All optimization logic is encapsulated in the optimizer object. Here, we use the SGD optimizer; additionally, there are many different optimizers available in PyTorch such as ADAM and RMSProp, that work better for different kinds of models and data.\n",
        "\n",
        "We initialize the optimizer by **registering the model’s parameters** that need to be trained, and passing in the **learning rate hyperparameter**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVZHgyi1x96X"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eP1Jmy_ygVu"
      },
      "source": [
        "Inside the training loop, optimization happens in three steps:\n",
        "\n",
        "1. Call optimizer.zero_grad() to **reset the gradients of model parameters**. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
        "\n",
        "2. **Backpropagate the prediction loss** with a call to loss.backward(). PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
        "\n",
        "3. Once we have our gradients, we call optimizer.step() to **adjust the parameters** by the gradients collected in the backward pass."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va8teUI_yv3P"
      },
      "source": [
        "## Full training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0vXWA8nyZ0D"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute the prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2GpV7NVzYGd"
      },
      "source": [
        "## Full testing loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qB4TaHEKzVvu"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalisation and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(\n",
        "        f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2w54rd80AXO"
      },
      "source": [
        "We initialize the loss function and optimizer, and pass it to train_loop and test_loop. Feel free to increase the number of epochs to track the model’s improving performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xJvDE0Ez69a",
        "outputId": "2cc58c97-0e6a-4977-e3cb-b8706fe06a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.300085  [   64/60000]\n",
            "loss: 2.292223  [ 6464/60000]\n",
            "loss: 2.294612  [12864/60000]\n",
            "loss: 2.283162  [19264/60000]\n",
            "loss: 2.279641  [25664/60000]\n",
            "loss: 2.282388  [32064/60000]\n",
            "loss: 2.272002  [38464/60000]\n",
            "loss: 2.273226  [44864/60000]\n",
            "loss: 2.253159  [51264/60000]\n",
            "loss: 2.254613  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 42.3%, Avg loss: 2.251972 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.245827  [   64/60000]\n",
            "loss: 2.235991  [ 6464/60000]\n",
            "loss: 2.247810  [12864/60000]\n",
            "loss: 2.227066  [19264/60000]\n",
            "loss: 2.221572  [25664/60000]\n",
            "loss: 2.218985  [32064/60000]\n",
            "loss: 2.211084  [38464/60000]\n",
            "loss: 2.212244  [44864/60000]\n",
            "loss: 2.221478  [51264/60000]\n",
            "loss: 2.179286  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 56.8%, Avg loss: 2.185574 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.170178  [   64/60000]\n",
            "loss: 2.178241  [ 6464/60000]\n",
            "loss: 2.150765  [12864/60000]\n",
            "loss: 2.124737  [19264/60000]\n",
            "loss: 2.152570  [25664/60000]\n",
            "loss: 2.144791  [32064/60000]\n",
            "loss: 2.120190  [38464/60000]\n",
            "loss: 2.105145  [44864/60000]\n",
            "loss: 2.076928  [51264/60000]\n",
            "loss: 2.076045  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.0%, Avg loss: 2.069895 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.064329  [   64/60000]\n",
            "loss: 2.057597  [ 6464/60000]\n",
            "loss: 2.038524  [12864/60000]\n",
            "loss: 1.974392  [19264/60000]\n",
            "loss: 2.020957  [25664/60000]\n",
            "loss: 1.987805  [32064/60000]\n",
            "loss: 1.882518  [38464/60000]\n",
            "loss: 1.968383  [44864/60000]\n",
            "loss: 1.877202  [51264/60000]\n",
            "loss: 1.885270  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 69.3%, Avg loss: 1.872174 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.820463  [   64/60000]\n",
            "loss: 1.846708  [ 6464/60000]\n",
            "loss: 1.837087  [12864/60000]\n",
            "loss: 1.757153  [19264/60000]\n",
            "loss: 1.713511  [25664/60000]\n",
            "loss: 1.662237  [32064/60000]\n",
            "loss: 1.732018  [38464/60000]\n",
            "loss: 1.663088  [44864/60000]\n",
            "loss: 1.622883  [51264/60000]\n",
            "loss: 1.549651  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 74.3%, Avg loss: 1.579702 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.481672  [   64/60000]\n",
            "loss: 1.621238  [ 6464/60000]\n",
            "loss: 1.566664  [12864/60000]\n",
            "loss: 1.403534  [19264/60000]\n",
            "loss: 1.475005  [25664/60000]\n",
            "loss: 1.438483  [32064/60000]\n",
            "loss: 1.452724  [38464/60000]\n",
            "loss: 1.299031  [44864/60000]\n",
            "loss: 1.393918  [51264/60000]\n",
            "loss: 1.243907  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 1.258843 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.225866  [   64/60000]\n",
            "loss: 1.244359  [ 6464/60000]\n",
            "loss: 1.296411  [12864/60000]\n",
            "loss: 1.201280  [19264/60000]\n",
            "loss: 1.221399  [25664/60000]\n",
            "loss: 1.128611  [32064/60000]\n",
            "loss: 1.055395  [38464/60000]\n",
            "loss: 0.969901  [44864/60000]\n",
            "loss: 0.938652  [51264/60000]\n",
            "loss: 0.955977  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg loss: 1.001407 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.055537  [   64/60000]\n",
            "loss: 0.964503  [ 6464/60000]\n",
            "loss: 0.974892  [12864/60000]\n",
            "loss: 0.847950  [19264/60000]\n",
            "loss: 0.947378  [25664/60000]\n",
            "loss: 1.056584  [32064/60000]\n",
            "loss: 0.746905  [38464/60000]\n",
            "loss: 0.950663  [44864/60000]\n",
            "loss: 0.907195  [51264/60000]\n",
            "loss: 0.803613  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.0%, Avg loss: 0.828166 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.955183  [   64/60000]\n",
            "loss: 0.607666  [ 6464/60000]\n",
            "loss: 0.780492  [12864/60000]\n",
            "loss: 0.751392  [19264/60000]\n",
            "loss: 0.785876  [25664/60000]\n",
            "loss: 0.871002  [32064/60000]\n",
            "loss: 0.695686  [38464/60000]\n",
            "loss: 0.846741  [44864/60000]\n",
            "loss: 0.687934  [51264/60000]\n",
            "loss: 0.774802  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.2%, Avg loss: 0.713437 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.733391  [   64/60000]\n",
            "loss: 0.817433  [ 6464/60000]\n",
            "loss: 0.717490  [12864/60000]\n",
            "loss: 0.649851  [19264/60000]\n",
            "loss: 0.942781  [25664/60000]\n",
            "loss: 0.616911  [32064/60000]\n",
            "loss: 0.654127  [38464/60000]\n",
            "loss: 0.687844  [44864/60000]\n",
            "loss: 0.584430  [51264/60000]\n",
            "loss: 0.564867  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.634853 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "YaiHC_ee0Mxw",
        "outputId": "56d0e4f9-9507-4c57-9e9a-3c20176329b0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 4\n",
            "\n",
            "Predicted class: tensor([4])\n"
          ]
        }
      ],
      "source": [
        "img, label = training_data[20]\n",
        "\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\\n\")\n",
        "\n",
        "img = img.to(device)\n",
        "logits = model(img)\n",
        "predicted_probabilities = nn.Softmax(dim=1)(logits)\n",
        "predicted_class = torch.argmax(predicted_probabilities, dim=1)\n",
        "print(f\"Predicted class: {predicted_class}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-0zo4un1oGq"
      },
      "source": [
        "# Save and load the model\n",
        "\n",
        "PyTorch models store the learned parameters in an internal state dictionary, called state_dict. **These can be saved using the torch.save method.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEisYOlX1ewU"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model_weights.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPMoBfgc18Nd"
      },
      "source": [
        "To load model weights, you need to create an instance of the same model first, and then load the parameters using `load_state_dict()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsM4JHMy13oH",
        "outputId": "4c8a287c-bed1-4dd2-88cd-8de095157719"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-110-3e20348b5a1b>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_new.load_state_dict(torch.load('model_weights.pth'))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_new = NeuralNetwork().to(device)\n",
        "\n",
        "model_new.load_state_dict(torch.load(\"model_weights.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "kARmbf6s2LWJ",
        "outputId": "09a37dc3-7a40-436d-e95d-50c02d3c2040"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 4\n",
            "\n",
            "Predicted class: tensor([4])\n"
          ]
        }
      ],
      "source": [
        "# Testing the newly loaded model, `model_new`\n",
        "\n",
        "img, label = training_data[20]\n",
        "\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\\n\")\n",
        "\n",
        "img = img.to(device)\n",
        "logits = model_new(img)\n",
        "predicted_probabilities = nn.Softmax(dim=1)(logits)\n",
        "predicted_class = torch.argmax(predicted_probabilities, dim=1)\n",
        "print(f\"Predicted class: {predicted_class}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCKMg_VuDY1M"
      },
      "source": [
        "# Recommended Reading and Other Resources\n",
        "1. [What is torch.nn really?](https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
        "2. [PyTorch Beginner Series](https://www.youtube.com/playlist?list=PL_lsbAsL_o2CTlGHgMxNrKhzP97BaG9ZN)\n",
        "\n",
        "This notebook is based on [Learn the Basics](https://pytorch.org/tutorials/beginner/basics/intro.html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
